{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from rapidfuzz import process, fuzz\n",
    "import matplotlib.pyplot as plt\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step1: Extract only the street name\n",
    "# Extract thing from we first see digit, until the first ,\n",
    "# So everything before and after street name should not be there\n",
    "def extract_street_name(job):\n",
    "    if pd.isna(job):\n",
    "        return None\n",
    "    # Use regex to remove everything before the first digit and stop at the first comma\n",
    "    match = re.search(r'\\d.*?(?=,|$)', job)\n",
    "    return match.group(0).strip() if match else job.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional steps for street\n",
    "# Step 1: Standardize street names in both sheet using a dictionary of replacements\n",
    "def standardize_street_names_regex(name):\n",
    "    if pd.isna(name):\n",
    "        return None\n",
    "    replacements = {\n",
    "        r\"\\bDr\\b\\.?\": \"Drive\",\n",
    "        r\"\\bLn\\b\\.?\": \"Lane\",\n",
    "        r\"\\bSt\\b\\.?\": \"Street\",\n",
    "        r\"\\bAve\\b\\.?\": \"Avenue\",\n",
    "        r\"\\bBlvd\\b\\.?\": \"Boulevard\",\n",
    "        r\"\\bCt\\b\\.?\": \"Court\",\n",
    "        r\"\\bRd\\b\\.?\": \"Road\",\n",
    "        r\"\\bPl\\b\\.?\": \"Place\",\n",
    "    }\n",
    "    for short, full in replacements.items():\n",
    "        name = pd.Series([name]).str.replace(short, full, regex=True).iloc[0]\n",
    "    return name.lower().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the Salesforce Excel file\n",
    "salesforce_path = r\"C:\\Users\\Yijia Wang\\Desktop\\Open-House-Analysis\\Data\\Feb_2025\\raw_data\\All Move Ins Jan 2025.xlsx\"\n",
    "\n",
    "# Reading the Excel file into a DataFrame\n",
    "salesforce = pd.read_excel(salesforce_path)\n",
    "salesforce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "salesforce['Street Name'] = salesforce['Address'].apply(extract_street_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "salesforce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "salesforce['Standardized Street Name'] = salesforce['Street Name'].apply(standardize_street_names_regex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "salesforce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "salesforce.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FOR ATL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use second way to check ATL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "# 11,186\n",
    "purchase_orders_path_atl_all = r\"C:\\Users\\Yijia Wang\\Desktop\\Open-House-Analysis\\Data\\Feb_2025\\raw_data\\PurchaseOrders_Jan_2025.xlsx\"\n",
    "purchase_orders_atl_all = pd.read_excel(purchase_orders_path_atl_all, skiprows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "purchase_orders_atl_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "purchase_orders_atl_all.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "purchase_orders_atl_all = purchase_orders_atl_all.dropna(subset=['Cost'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "purchase_orders_atl_all['Street Name'] = purchase_orders_atl_all['Job'].apply(extract_street_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This for debug only to check if the street name is mapped correctly\n",
    "print(purchase_orders_atl_all[['Job', 'Street Name']].drop_duplicates())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "purchase_orders_atl_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "purchase_orders_atl_all['Street Name'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "purchase_orders_atl_all[purchase_orders_atl_all['Cost'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "purchase_orders_atl_all = purchase_orders_atl_all.dropna(subset=['Title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "purchase_orders_atl_all[purchase_orders_atl_all['Title'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "purchase_orders_atl_all[purchase_orders_atl_all['Street Name'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "purchase_orders_atl_all[purchase_orders_atl_all['Job'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# purchase_orders_atl_all[purchase_orders_atl_all['Street Name'] == \"1104 Sallete Ct\"].sort_values(by='Created Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the first 10 unique Job name \n",
    "print(\"Unique Job Names:\", purchase_orders_atl_all['Job'].nunique())\n",
    "print(purchase_orders_atl_all['Job'].unique()[:10])  # Print first 10 unique job names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the Job name for better looping\n",
    "purchase_orders_atl_all['Job'] = purchase_orders_atl_all['Job'].str.strip().str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Initialize a DataFrame to store results\n",
    "final_results_atl = pd.DataFrame(columns=purchase_orders_atl_all.columns)\n",
    "\n",
    "# Step 3: Loop through unique Job names\n",
    "for job_name in purchase_orders_atl_all['Job'].unique():\n",
    "    # Filter rows for the current job name\n",
    "    job_rows = purchase_orders_atl_all[purchase_orders_atl_all['Job'] == job_name]\n",
    "    \n",
    "    # Sort rows by \"Created Date\" from earliest to latest\n",
    "    job_rows = job_rows.sort_values(by='Created Date')\n",
    "\n",
    "    # Search for \"touch\" in the \"Title\" column (case-insensitive)\n",
    "    touch_rows = job_rows[job_rows['Title'].str.contains(r'touch', case=False, na=False)]\n",
    "    \n",
    "    if not touch_rows.empty:\n",
    "        # Get the date of the first \"touch\" match\n",
    "        first_touch_date = touch_rows.iloc[0]['Created Date']\n",
    "        \n",
    "        # Return all rows below the \"touch\" row (Created Date later)\n",
    "        later_rows = job_rows[\n",
    "            (job_rows['Created Date'] > first_touch_date) &  # Strictly later\n",
    "            (~job_rows.index.isin(touch_rows.index))  # Exclude the actual \"touch\" row\n",
    "            ].copy()\n",
    "        \n",
    "        if not later_rows.empty:\n",
    "            # Separate positive and negative costs\n",
    "            positive_rows = later_rows[later_rows['Cost'] > 0].copy()\n",
    "            negative_rows = later_rows[later_rows['Cost'] < 0].copy()\n",
    "            \n",
    "            # Create a count dictionary for the absolute values of negative costs\n",
    "            from collections import Counter\n",
    "            negative_counts = Counter(negative_rows['Cost'].abs().tolist())\n",
    "            \n",
    "            # Iterate through each positive row and adjust if a match is found\n",
    "            adjusted_positive_rows = []\n",
    "            for _, pos_row in positive_rows.iterrows():\n",
    "                pos_cost = pos_row['Cost']\n",
    "                # If there's a matching negative cost, set this positive cost to 0\n",
    "                if negative_counts[pos_cost] > 0:\n",
    "                    negative_counts[pos_cost] -= 1\n",
    "                    pos_row['Cost'] = 0  # set cost to zero instead of removing the row\n",
    "                # Add the (possibly adjusted) positive row to the final list\n",
    "                adjusted_positive_rows.append(pos_row)\n",
    "            \n",
    "            # Convert the adjusted positives back to a DataFrame\n",
    "            adjusted_positive_df = pd.DataFrame(adjusted_positive_rows, columns=positive_rows.columns)\n",
    "            \n",
    "            # Since we are not including negative rows in the final results,\n",
    "            # we only append the adjusted positive rows.\n",
    "            final_results_atl = pd.concat([final_results_atl, adjusted_positive_df], ignore_index=True)\n",
    "\n",
    "# final_results_atl now contains the rows after offsetting negative costs by zeroing out the matching positive costs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_results_atl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter rows where 'Title' contains 'touch'\n",
    "final_results_atl[final_results_atl['Title'].str.contains(r'touch', case=False, na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_results_atl.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_results_atl[final_results_atl['Street Name'] == \"1104 Sallete Ct\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_results_atl.shape # There are 1303 WOs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_results_atl['Standardized Street Name'] = final_results_atl['Street Name'].apply(standardize_street_names_regex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Format Created Date to MM/YYYY\n",
    "final_results_atl['Created Date'] = pd.to_datetime(final_results_atl['Created Date'], errors='coerce')\n",
    "final_results_atl['Month/Year'] = final_results_atl['Created Date'].dt.strftime('%m/%Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Perform the merge with standardized street names\n",
    "merged_data_standardized_atl = final_results_atl.merge(\n",
    "    salesforce[['Standardized Street Name', 'Cleaned Name', 'Area Picklist']],\n",
    "    left_on='Standardized Street Name',\n",
    "    right_on='Standardized Street Name',\n",
    "    how='inner'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merged_data_standardized_atl[merged_data_standardized_atl['Street Name'] == \"1104 Sallete Ct\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data_standardized_atl= merged_data_standardized_atl[merged_data_standardized_atl['Area Picklist'] == 'Atlanta']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data_standardized_atl['Cleaned Name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names_ATL = ['Clifford Senter',  'Jason Bishop', 'Jimmy Knox', 'Kirsten Davis', 'Nicholas Beuoy', 'Nicole Quiles', 'Paris Paggett', 'Ryan Worrell', 'Shaamar Moore', 'Trevor Stevens']\n",
    "merged_data_standardized_atl = merged_data_standardized_atl[merged_data_standardized_atl['Cleaned Name'].isin(names_ATL)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data_standardized_atl.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the data for further use\n",
    "export_columns = [\n",
    "    \"Title\",\n",
    "    \"Street Name\", \n",
    "    \"Standardized Street Name\", \n",
    "    \"Created Date\", \n",
    "    \"Month/Year\", \n",
    "    \"Cleaned Name\", \n",
    "    \"Area Picklist\", \n",
    "    \"Cost\"\n",
    "]\n",
    "export_data_atl = merged_data_standardized_atl[export_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_data_atl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ATL_agg = export_data_atl\n",
    "\n",
    "# Calculate the average cost for each person per month\n",
    "df_ATL_avg = df_ATL_agg.groupby(['Month/Year', 'Cleaned Name'], as_index=False)['Cost'].mean()\n",
    "\n",
    "# Pivot the data for plotting\n",
    "df_ATL_pivot = df_ATL_avg.pivot(index='Month/Year', columns='Cleaned Name', values='Cost')\n",
    "\n",
    "df_ATL_pivot.index = pd.to_datetime(df_ATL_pivot.index, format='%m/%Y')\n",
    "df_ATL_pivot = df_ATL_pivot.sort_index()\n",
    "\n",
    "# Calculate the overall average cost for ATL\n",
    "overall_ATL_avg_cost = df_ATL_agg['Cost'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting\n",
    "plt.figure(figsize=(14, 8))\n",
    "for column in df_ATL_pivot.columns:\n",
    "    plt.plot(df_ATL_pivot.index, df_ATL_pivot[column], marker='o', label=column)\n",
    "    \n",
    "# Add a horizontal dashed line for the overall average cost\n",
    "plt.axhline(y=overall_ATL_avg_cost, color='grey', linestyle='--', linewidth=1, label=f'Overall Avg Cost (${overall_ATL_avg_cost:.2f})')\n",
    "\n",
    "plt.title('ATL Average Monthly Move in Issues Cost per Field Super', fontsize=16)\n",
    "plt.xlabel('Date', fontsize=14)\n",
    "plt.ylabel('Average Cost ($)', fontsize=14)\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend(title='Project Manager', fontsize=10, loc='upper right', frameon=True)\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure 'Month/Year' column is in datetime format\n",
    "export_data_atl['Month/Year'] = pd.to_datetime(export_data_atl['Month/Year'], format='%m/%Y', errors='coerce')\n",
    "\n",
    "export_data_atl_Jan = export_data_atl[export_data_atl['Month/Year'] == '2025-01']\n",
    "export_data_atl_Jan "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ATL_agg = export_data_atl_Jan\n",
    "\n",
    "# Calculate the average cost for each person per month\n",
    "df_ATL_avg = df_ATL_agg.groupby(['Month/Year', 'Cleaned Name'], as_index=False)['Cost'].mean()\n",
    "\n",
    "# Pivot the data for plotting\n",
    "df_ATL_pivot = df_ATL_avg.pivot(index='Month/Year', columns='Cleaned Name', values='Cost')\n",
    "\n",
    "df_ATL_pivot.index = pd.to_datetime(df_ATL_pivot.index, format='%m/%Y')\n",
    "df_ATL_pivot = df_ATL_pivot.sort_index()\n",
    "\n",
    "# Calculate the overall average cost for ATL\n",
    "overall_ATL_avg_cost = df_ATL_agg['Cost'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_ATL_avg_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ATL_avg "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r\"C:\\Users\\Yijia Wang\\Desktop\\Open-House-Analysis\\Data\\Feb_2025\\archive\\WO_Cost_Jan2025_2_25_atl.xlsx\"\n",
    "export_data_atl_Jan.to_excel(path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FOR TX:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Data\n",
    "purchase_orders_path_tx_all = r\"C:\\Users\\Yijia Wang\\Desktop\\Open-House-Analysis\\Data\\Feb_2025\\raw_data\\PurchaseOrders_tx_Jan_2025.xlsx\"\n",
    "\n",
    "# Read the data from the new files\n",
    "purchase_orders_tx_all = pd.read_excel(purchase_orders_path_tx_all, skiprows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "purchase_orders_tx_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "purchase_orders_tx_all['Street Name'] = purchase_orders_tx_all['Job'].apply(extract_street_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "purchase_orders_tx_all['Street Name'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the Job name for better looping\n",
    "purchase_orders_atl_all['Job'] = purchase_orders_atl_all['Job'].str.strip().str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Initialize a DataFrame to store results\n",
    "# Updated the loop to not only for each Job, show rows created after first see touch\n",
    "# but also remove all negatives and also set positive value with same amount of negative cost found to zero\n",
    "final_results_tx = pd.DataFrame(columns=purchase_orders_tx_all.columns)\n",
    "\n",
    "# Step 3: Loop through unique Job names\n",
    "for job_name_tx in purchase_orders_tx_all['Job'].unique():\n",
    "    # Filter rows for the current job name\n",
    "    job_rows_tx = purchase_orders_tx_all[purchase_orders_tx_all['Job'] == job_name_tx]\n",
    "    \n",
    "    # Sort rows by \"Created Date\" from earliest to latest\n",
    "    job_rows_tx = job_rows_tx.sort_values(by='Created Date')\n",
    "    \n",
    "    # Search for \"touch\" in the \"Title\" column (case-insensitive)\n",
    "    touch_rows_tx = job_rows_tx[job_rows_tx['Title'].str.contains(r'touch', case=False, na=False)]\n",
    "    \n",
    "    if not touch_rows_tx.empty:\n",
    "        # Get the date of the first \"touch\" match\n",
    "        first_touch_date_tx = touch_rows_tx.iloc[0]['Created Date']\n",
    "        \n",
    "        # Return all rows below the \"touch\" row (Created Date later)\n",
    "        # Return all rows below the \"touch\" row (Created Date later)\n",
    "        later_rows_tx = job_rows_tx[\n",
    "            (job_rows_tx['Created Date'] > first_touch_date_tx) &  # Strictly later\n",
    "            (~job_rows_tx.index.isin(touch_rows_tx.index))  # Exclude the actual \"touch\" row\n",
    "            ].copy()\n",
    "        \n",
    "        if not later_rows_tx.empty:\n",
    "            # Separate into positive and negative rows\n",
    "            positive_rows = later_rows_tx[later_rows_tx['Cost'] > 0].copy()\n",
    "            negative_rows = later_rows_tx[later_rows_tx['Cost'] < 0].copy()\n",
    "            \n",
    "            # Get a count of the absolute values of negative costs\n",
    "            from collections import Counter\n",
    "            negative_counts = Counter(negative_rows['Cost'].abs().tolist())\n",
    "\n",
    "            # Keep track of final positive rows after adjustment\n",
    "            adjusted_positive_rows = []\n",
    "            \n",
    "            # Iterate through each positive row to see if it can be offset by a negative\n",
    "            for _, pos_row in positive_rows.iterrows():\n",
    "                pos_cost = pos_row['Cost']\n",
    "                # If there's a matching negative cost available, set the positive cost to 0\n",
    "                if negative_counts[pos_cost] > 0:\n",
    "                    negative_counts[pos_cost] -= 1\n",
    "                    pos_row['Cost'] = 0\n",
    "                # Add the (possibly adjusted) positive row to the final list\n",
    "                adjusted_positive_rows.append(pos_row)\n",
    "            \n",
    "            # Convert the adjusted positives back to a DataFrame\n",
    "            adjusted_positive_df = pd.DataFrame(adjusted_positive_rows, columns=positive_rows.columns)\n",
    "            \n",
    "            # Append these rows to the final results\n",
    "            final_results_tx = pd.concat([final_results_tx, adjusted_positive_df], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter rows where 'Title' contains 'touch'\n",
    "final_results_tx[final_results_tx['Title'].str.contains(r'touch', case=False, na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_results_tx['Standardized Street Name'] = final_results_tx['Street Name'].apply(standardize_street_names_regex)\n",
    "final_results_tx.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_results_tx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Format Created Date to MM/YYYY\n",
    "final_results_tx['Created Date'] = pd.to_datetime(final_results_tx['Created Date'], errors='coerce')\n",
    "final_results_tx['Month/Year'] = final_results_tx['Created Date'].dt.strftime('%m/%Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_results_tx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Perform the merge with standardized street names\n",
    "merged_data_standardized_tx = final_results_tx.merge(\n",
    "    salesforce[['Standardized Street Name', 'Cleaned Name', 'Area Picklist']],\n",
    "    left_on='Standardized Street Name',\n",
    "    right_on='Standardized Street Name',\n",
    "    how='inner'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data_standardized_tx.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data_standardized_tx[merged_data_standardized_tx['Cost'] < 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For DFW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data_standardized_dfw= merged_data_standardized_tx[merged_data_standardized_tx['Area Picklist'] == 'DFW']\n",
    "merged_data_standardized_dfw['Cleaned Name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data_standardized_dfw= merged_data_standardized_tx[merged_data_standardized_tx['Area Picklist'] == 'DFW']\n",
    "names_DFW = ['Chase Wilson',  'Christopher Poujol','Christopher Silbaugh', 'Gilbert Sifuentes', 'Ricardo Martinez', 'Michael Woodson', 'Oscar Flores', 'William Goodson', 'William MacQueenette', 'Damon Nash']\n",
    "merged_data_standardized_dfw = merged_data_standardized_dfw[merged_data_standardized_dfw['Cleaned Name'].isin(names_DFW)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data_standardized_dfw['Cleaned Name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_missing_cleaned_name_dfw = merged_data_standardized_dfw['Cleaned Name'].isna().sum()\n",
    "num_missing_cleaned_name_dfw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the data for further use\n",
    "export_columns = [\n",
    "    \"Title\",\n",
    "    \"Street Name\", \n",
    "    \"Standardized Street Name\", \n",
    "    \"Created Date\", \n",
    "    \"Month/Year\", \n",
    "    \"Cleaned Name\", \n",
    "    \"Area Picklist\", \n",
    "    \"Cost\"\n",
    "]\n",
    "export_data_dfw = merged_data_standardized_dfw[export_columns]\n",
    "# # Define the full path to the 'Data' folder\n",
    "# export_path_tx = r\"C:\\Users\\Yijia Wang\\Desktop\\Open-House-Analysis\\Data\\TX_PurchaseOrders_AfterStandardizedMerge_Ordered.csv\"\n",
    "\n",
    "# # Export the data to the specified folder\n",
    "# export_data.to_csv(export_path_tx, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_DFW.to_csv(\"df_DFW.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by WO_Number, Month/Year, and Cleaned Name, and sum the costs for duplicate work orders\n",
    "# df_DFW_agg = df_DFW.groupby(['WO_Number', 'Month/Year', 'Cleaned Name'], as_index=False)['Cost'].sum()\n",
    "# df_ATL_agg.to_csv(\"df_ATL_agg.csv\")\n",
    "\n",
    "df_DFW_agg = export_data_dfw\n",
    "\n",
    "# Calculate the average cost for each person per month\n",
    "df_DFW_avg = df_DFW_agg.groupby(['Month/Year', 'Cleaned Name'], as_index=False)['Cost'].mean()\n",
    "\n",
    "# Pivot the data for plotting\n",
    "df_DFW_pivot = df_DFW_avg.pivot(index='Month/Year', columns='Cleaned Name', values='Cost')\n",
    "\n",
    "df_DFW_pivot.index = pd.to_datetime(df_DFW_pivot.index, format='%m/%Y')\n",
    "df_DFW_pivot = df_DFW_pivot.sort_index()\n",
    "\n",
    "# Calculate the overall average cost for DFW\n",
    "overall_DFW_avg_cost = df_DFW_agg['Cost'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_DFW_avg[df_DFW_avg['Cost'] < 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_data_dfw[(export_data_dfw['Month/Year'] == '08/2024') & (export_data_dfw['Cleaned Name'] == 'William Goodson')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting\n",
    "plt.figure(figsize=(14, 8))\n",
    "for column in df_DFW_pivot.columns:\n",
    "    plt.plot(df_DFW_pivot.index, df_DFW_pivot[column], marker='o', label=column)\n",
    "\n",
    "# Add a horizontal dashed line for the overall average cost\n",
    "plt.axhline(y=overall_DFW_avg_cost, color='grey', linestyle='--', linewidth=1, label=f'Overall Avg Cost (${overall_DFW_avg_cost:.2f})')\n",
    "\n",
    "plt.title('DFW Average Monthly Move in Issues Cost per Field Super', fontsize=16)\n",
    "plt.xlabel('Date', fontsize=14)\n",
    "plt.ylabel('Average Cost ($)', fontsize=14)\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend(title='Project Manager', fontsize=10, loc='upper right', frameon=True)\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting\n",
    "# Make the plot to same range\n",
    "plt.figure(figsize=(14, 8))\n",
    "for column in df_DFW_pivot.columns:\n",
    "    plt.plot(df_DFW_pivot.index, df_DFW_pivot[column], marker='o', label=column)\n",
    "\n",
    "plt.title('DFW Average Cost Trend', fontsize=16)\n",
    "plt.xlabel('Date', fontsize=14)\n",
    "plt.ylabel('Average Cost ($)', fontsize=14)\n",
    "plt.xticks(rotation=45)\n",
    "plt.ylim(0, 2000)  # Set the y-axis range from 0 to 2000\n",
    "plt.legend(title='Cleaned Name', fontsize=10, bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure 'Month/Year' column is in datetime format\n",
    "export_data_dfw['Month/Year'] = pd.to_datetime(export_data_dfw['Month/Year'], format='%m/%Y', errors='coerce')\n",
    "\n",
    "export_data_dfw_Jan = export_data_dfw[export_data_dfw['Month/Year'] == '2025-01']\n",
    "export_data_dfw_Jan "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = r\"C:\\Users\\Yijia Wang\\Desktop\\Open-House-Analysis\\Data\\Feb_2025\\archive\\WO_Cost_Jan2025_2_25_dfw.xlsx\"\n",
    "# export_data_dfw_Jan.to_excel(path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For HOU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data_standardized_hou= merged_data_standardized_tx[merged_data_standardized_tx['Area Picklist'] == 'Houston']\n",
    "merged_data_standardized_hou['Cleaned Name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data_standardized_hou= merged_data_standardized_tx[merged_data_standardized_tx['Area Picklist'] == 'Houston']\n",
    "names_HOU = ['Angel Rosas', 'Tony Chavez', 'Bryant Johnson', 'Bryce Porter', 'Kenin Vargas', 'Kenneth Lee', 'Steve Wentz']\n",
    "merged_data_standardized_hou = merged_data_standardized_hou[merged_data_standardized_hou['Cleaned Name'].isin(names_HOU)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data_standardized_hou['Cleaned Name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_missing_cleaned_name_hou = merged_data_standardized_hou['Cleaned Name'].isna().sum()\n",
    "num_missing_cleaned_name_hou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_data_hou = merged_data_standardized_hou[export_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_HOU_agg = export_data_hou\n",
    "\n",
    "# Calculate the average cost for each person per month\n",
    "df_HOU_avg = df_HOU_agg.groupby(['Month/Year', 'Cleaned Name'], as_index=False)['Cost'].mean()\n",
    "\n",
    "# Pivot the data for plotting\n",
    "df_HOU_pivot = df_HOU_avg.pivot(index='Month/Year', columns='Cleaned Name', values='Cost')\n",
    "\n",
    "df_HOU_pivot.index = pd.to_datetime(df_HOU_pivot.index, format='%m/%Y')\n",
    "df_HOU_pivot = df_HOU_pivot.sort_index()\n",
    "\n",
    "# Calculate the overall average cost for HOU\n",
    "overall_HOU_avg_cost = df_HOU_agg['Cost'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting\n",
    "plt.figure(figsize=(14, 8))\n",
    "for column in df_HOU_pivot.columns:\n",
    "    plt.plot(df_HOU_pivot.index, df_HOU_pivot[column], marker='o', label=column)\n",
    "\n",
    "# Add a horizontal dashed line for the overall average cost\n",
    "plt.axhline(y=overall_HOU_avg_cost, color='grey', linestyle='--', linewidth=1, label=f'Overall Avg Cost (${overall_HOU_avg_cost:.2f})')\n",
    "\n",
    "plt.title('HOU Average Monthly Move in Issues Cost per Field Super', fontsize=16)\n",
    "plt.xlabel('Date', fontsize=14)\n",
    "plt.ylabel('Average Cost ($)', fontsize=14)\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend(title='Project Manager', fontsize=10, loc='upper left', frameon=True)\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure 'Month/Year' column is in datetime format\n",
    "export_data_hou['Month/Year'] = pd.to_datetime(export_data_hou['Month/Year'], format='%m/%Y', errors='coerce')\n",
    "\n",
    "export_data_hou_Jan = export_data_hou[export_data_hou['Month/Year'] == '2025-01']\n",
    "export_data_hou_Jan "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = r\"C:\\Users\\Yijia Wang\\Desktop\\Open-House-Analysis\\Data\\Feb_2025\\archive\\WO_Cost_Jan2025_2_25_hou.xlsx\"\n",
    "# export_data_hou_Jan.to_excel(path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Being Used:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_data_atl_Jan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_data_atl['Cost'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_data_dfw_Jan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_data_dfw ['Cost'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_data_hou_Jan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_data_hou['Cost'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "appended_table = pd.concat([export_data_atl_Jan, export_data_dfw_Jan, export_data_hou_Jan], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "appended_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show overall graph\n",
    "average_cost = (\n",
    "    appended_table.groupby(['Month/Year', 'Area Picklist'])['Cost']\n",
    "    .mean()\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Pivot the data to prepare for plotting\n",
    "pivot_data = average_cost.pivot(index='Month/Year', columns='Area Picklist', values='Cost')\n",
    "\n",
    "# Plotting the line graph\n",
    "plt.figure(figsize=(10, 6))\n",
    "for column in pivot_data.columns:\n",
    "    plt.plot(pivot_data.index, pivot_data[column],  marker='o', label=column)\n",
    "\n",
    "plt.title('Average Cost by Area Picklist Over Time')\n",
    "plt.xlabel('Month/Year')\n",
    "plt.ylabel('Average Cost')\n",
    "plt.legend(title='Project Manager', fontsize=10, loc='upper right', frameon=True)\n",
    "plt.grid(True)\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "appended_table['Month/Year'] = pd.to_datetime(appended_table['Month/Year'],  format=\"%m/%Y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "appended_table.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "appended_table[appended_table['Title'].str.contains(r'touch', case=False, na=False)] # Make sure touch row itself is removed from final table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combined_path = r\"C:\\Users\\Yijia Wang\\Desktop\\Open-House-Analysis\\Summary\\monthly_move_in_issues\\Feb_2024\\WO_Cost_Jan2025.xlsx\"\n",
    "# appended_table.to_excel(combined_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "appended_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's try monthly sum for all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ATL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the sum cost for each person per month\n",
    "df_ATL_sum = df_ATL_agg.groupby(['Month/Year', 'Cleaned Name'], as_index=False)['Cost'].sum()\n",
    "\n",
    "# Pivot the data for plotting\n",
    "df_ATL_pivot_sum = df_ATL_sum.pivot(index='Month/Year', columns='Cleaned Name', values='Cost')\n",
    "\n",
    "df_ATL_pivot_sum.index = pd.to_datetime(df_ATL_pivot_sum.index, format='%m/%Y')\n",
    "df_ATL_pivot_sum = df_ATL_pivot_sum.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting\n",
    "plt.figure(figsize=(14, 8))\n",
    "for column in df_ATL_pivot_sum.columns:\n",
    "    plt.plot(df_ATL_pivot_sum.index, df_ATL_pivot_sum[column], marker='o', label=column)\n",
    "\n",
    "plt.title('ATL Sum Cost Trend', fontsize=16)\n",
    "plt.xlabel('Date', fontsize=14)\n",
    "plt.ylabel('Sum Cost ($)', fontsize=14)\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend(title='Cleaned Name', fontsize=10, bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### DFW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the sum cost for each person per month\n",
    "df_DFW_sum = df_DFW_agg.groupby(['Month/Year', 'Cleaned Name'], as_index=False)['Cost'].sum()\n",
    "\n",
    "# Pivot the data for plotting\n",
    "df_DFW_pivot_sum = df_DFW_sum.pivot(index='Month/Year', columns='Cleaned Name', values='Cost')\n",
    "\n",
    "df_DFW_pivot_sum.index = pd.to_datetime(df_DFW_pivot_sum.index, format='%m/%Y')\n",
    "df_DFW_pivot_sum = df_DFW_pivot_sum.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting\n",
    "plt.figure(figsize=(14, 8))\n",
    "for column in df_DFW_pivot_sum.columns:\n",
    "    plt.plot(df_DFW_pivot_sum.index, df_DFW_pivot_sum[column], marker='o', label=column)\n",
    "\n",
    "plt.title('DFW Sum Cost Trend', fontsize=16)\n",
    "plt.xlabel('Date', fontsize=14)\n",
    "plt.ylabel('Sum Cost ($)', fontsize=14)\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend(title='Cleaned Name', fontsize=10, bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### HOU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the sum cost for each person per month\n",
    "df_HOU_sum = df_HOU_agg.groupby(['Month/Year', 'Cleaned Name'], as_index=False)['Cost'].sum()\n",
    "\n",
    "# Pivot the data for plotting\n",
    "df_HOU_pivot_sum = df_HOU_sum.pivot(index='Month/Year', columns='Cleaned Name', values='Cost')\n",
    "\n",
    "df_HOU_pivot_sum.index = pd.to_datetime(df_HOU_pivot_sum.index, format='%m/%Y')\n",
    "df_HOU_pivot_sum = df_HOU_pivot_sum.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting\n",
    "plt.figure(figsize=(14, 8))\n",
    "for column in df_HOU_pivot_sum.columns:\n",
    "    plt.plot(df_HOU_pivot_sum.index, df_HOU_pivot_sum[column], marker='o', label=column)\n",
    "\n",
    "plt.title('HOU Sum Cost Trend', fontsize=16)\n",
    "plt.xlabel('Date', fontsize=14)\n",
    "plt.ylabel('Sum Cost ($)', fontsize=14)\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend(title='Cleaned Name', fontsize=10, bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show overall graph\n",
    "sum_cost = (\n",
    "    appended_table.groupby(['Month/Year', 'Area Picklist'])['Cost']\n",
    "    .sum()\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Pivot the data to prepare for plotting\n",
    "pivot_data_sum = sum_cost.pivot(index='Month/Year', columns='Area Picklist', values='Cost')\n",
    "\n",
    "# Plotting the line graph\n",
    "plt.figure(figsize=(10, 6))\n",
    "for column in pivot_data_sum.columns:\n",
    "    plt.plot(pivot_data_sum.index, pivot_data_sum[column],  marker='o', label=column)\n",
    "\n",
    "plt.title('Sum Cost by Area Picklist Over Time')\n",
    "plt.xlabel('Month/Year')\n",
    "plt.ylabel('Average Cost')\n",
    "plt.legend(title='Area Picklist')\n",
    "plt.grid(True)\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's try distribution of cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram of Cost for Three Cities\n",
    "plt.figure(figsize=(15, 5))  # width=15, height=5\n",
    "# 1. Histogram for ATL\n",
    "plt.subplot(1, 3, 1)\n",
    "sns.histplot(data=df_ATL_agg, x='Cost', kde=False, bins=30, color='blue')\n",
    "plt.title('Atlanta Cost Distribution')\n",
    "plt.xlabel('Cost')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "# 2. Histogram for DFW\n",
    "plt.subplot(1, 3, 2)\n",
    "sns.histplot(data=df_DFW_agg, x='Cost', kde=False, bins=30, color='green')\n",
    "plt.title('DFW Cost Distribution')\n",
    "plt.xlabel('Cost')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "# 3. Histogram for HOU\n",
    "plt.subplot(1, 3, 3)\n",
    "sns.histplot(data=df_HOU_agg, x='Cost', kde=False, bins=30, color='red')\n",
    "plt.title('Houston Cost Distribution')\n",
    "plt.xlabel('Cost')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplot of Cost for three cities\n",
    "plt.figure(figsize=(15, 5))\n",
    "# Create a combined DataFrame with an identifier column for region if you want to show them in one plot.\n",
    "# Otherwise, you can just do separate subplots as shown here.\n",
    "\n",
    "# 1. Box Plot for ATL\n",
    "plt.subplot(1, 3, 1)\n",
    "sns.boxplot(y='Cost', data=df_ATL_agg, color='blue')\n",
    "plt.title('Atlanta Cost Distribution (Box Plot)')\n",
    "plt.ylabel('Cost')\n",
    "\n",
    "# 2. Box Plot for DFW\n",
    "plt.subplot(1, 3, 2)\n",
    "sns.boxplot(y='Cost', data=df_DFW_agg, color='green')\n",
    "plt.title('DFW Cost Distribution (Box Plot)')\n",
    "plt.ylabel('Cost')\n",
    "\n",
    "# 3. Box Plot for HOU\n",
    "plt.subplot(1, 3, 3)\n",
    "sns.boxplot(y='Cost', data=df_HOU_agg, color='red')\n",
    "plt.title('Houston Cost Distribution (Box Plot)')\n",
    "plt.ylabel('Cost')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KDE plot for three cities\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# 1. KDE for ATL\n",
    "plt.subplot(1, 3, 1)\n",
    "sns.kdeplot(data=df_ATL_agg, x='Cost', fill=True, color='blue')\n",
    "plt.title('ATL Cost Density')\n",
    "plt.xlabel('Cost')\n",
    "plt.ylabel('Density')\n",
    "\n",
    "# 2. KDE for DFW\n",
    "plt.subplot(1, 3, 2)\n",
    "sns.kdeplot(data=df_DFW_agg, x='Cost', fill=True, color='green')\n",
    "plt.title('DFW Cost Density')\n",
    "plt.xlabel('Cost')\n",
    "plt.ylabel('Density')\n",
    "\n",
    "# 3. KDE for HOU\n",
    "plt.subplot(1, 3, 3)\n",
    "sns.kdeplot(data=df_HOU_agg, x='Cost', fill=True, color='red')\n",
    "plt.title('HOU Cost Density')\n",
    "plt.xlabel('Cost')\n",
    "plt.ylabel('Density')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze correlations between costs and other factors\n",
    "\n",
    "# 1. Costs vs. Work Order Type\n",
    "cost_vs_type = appended_table.groupby('Title')['Cost'].mean().sort_values(ascending=False)\n",
    "\n",
    "# 2. Costs vs. Area\n",
    "cost_vs_area =appended_table.groupby('Area Picklist')['Cost'].mean().sort_values(ascending=False)\n",
    "\n",
    "# 3. Costs vs. Time of Year\n",
    "# Extract the month from the 'Month/Year' column\n",
    "appended_table['Month'] = pd.to_datetime(appended_table['Month/Year']).dt.month\n",
    "cost_vs_month = appended_table.groupby('Month')['Cost'].mean()\n",
    "# Analyze correlations between costs and other factors\n",
    "\n",
    "# 1. Costs vs. Work Order Type\n",
    "cost_vs_type = appended_table.groupby('Title')['Cost'].mean().sort_values(ascending=False)\n",
    "\n",
    "# 2. Costs vs. Area\n",
    "cost_vs_area = appended_table.groupby('Area Picklist')['Cost'].mean().sort_values(ascending=False)\n",
    "\n",
    "# 3. Costs vs. Time of Year\n",
    "# Extract the month from the 'Month/Year' column\n",
    "appended_table['Month'] = pd.to_datetime(appended_table['Month/Year']).dt.month\n",
    "cost_vs_month = appended_table.groupby('Month')['Cost'].mean()\n",
    "\n",
    "cost_vs_area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_vs_month"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
